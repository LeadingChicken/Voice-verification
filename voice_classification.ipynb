{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display and threading libraries\n",
    "from IPython.display import display, clear_output\n",
    "import ipywidgets as widgets\n",
    "from threading import Thread\n",
    "\n",
    "# audio libraries\n",
    "# import pyaudio # I hate this library\n",
    "import sounddevice as sd\n",
    "import torch\n",
    "import torchaudio\n",
    "from scipy.io.wavfile import write as writeAudio\n",
    "from speechbrain.inference.classifiers import EncoderClassifier\n",
    "from speechbrain.inference.enhancement import SpectralMaskEnhancement\n",
    "\n",
    "# supporting libraries\n",
    "import time\n",
    "from queue import Queue\n",
    "import json\n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialized parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CHANNELS': 1, 'FRAME_RATE': 44100, 'RECORD_SECONDS': 5, 'DATASET': 'voice_dataset.json', 'AUDIO_DIRECTORY': 'voice_dataset/', 'EMBED_THRESHOLD': 0.28, 'USER_THRESHOLD': 0.5, 'TEMP_AUDIOCHECK': False, 'TEMP_DIRECTORY': 'voiceClass_temp/', 'USERNAME': 'ID1'}\n"
     ]
    }
   ],
   "source": [
    "# core parameters in env file\n",
    "\n",
    "env_jsonFile = open(\"env.json\", \"r\")\n",
    "env = json.load(env_jsonFile)\n",
    "print(env)\n",
    "env_jsonFile.close()\n",
    "\n",
    "# ui parameters\n",
    "recordRecog_button = widgets.Button(\n",
    "    description='Record recognization',\n",
    "    disabled=False,\n",
    "    button_style='success',\n",
    "    tooltip='Record',\n",
    "    icon='microphone'\n",
    ")\n",
    "\n",
    "recordAdd_button = widgets.Button(\n",
    "    description='Record add dataset',\n",
    "    disabled=False,\n",
    "    button_style='success',\n",
    "    tooltip='Record',\n",
    "    icon='microphone'\n",
    ")\n",
    "\n",
    "stop_button = widgets.Button(\n",
    "    description='Stop',\n",
    "    disabled=False,\n",
    "    button_style='warning',\n",
    "    tooltip='Stop',\n",
    "    icon='stop'\n",
    ")\n",
    "\n",
    "audio_enhancer = SpectralMaskEnhancement.from_hparams(\n",
    "    source = \"speechbrain/metricgan-plus-voicebank\"\n",
    ")\n",
    "\n",
    "audio_classifier = EncoderClassifier.from_hparams(\n",
    "    source=\"speechbrain/spkrec-ecapa-voxceleb\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supporting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_randStr(length=15):\n",
    "    if length <= 0:\n",
    "        return None\n",
    "    \n",
    "    temp = \"\"\n",
    "    for _ in range(length):\n",
    "        a = random.randint(0, 61)\n",
    "        ch = None\n",
    "        if a < 26:\n",
    "            ch = chr(a + ord('A'))\n",
    "        elif a < 52:\n",
    "            ch = chr(a - 26 + ord('a'))\n",
    "        else:\n",
    "            ch = chr(a - 52 + ord('0'))\n",
    "\n",
    "        temp += str(ch)\n",
    "    \n",
    "    return \"audio_\"+ temp + \"_\" + str(int(time.time()*10000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Core functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_audio(recording):\n",
    "    # convert TEMP_REC into 1d vector\n",
    "    recording = np.array(recording).flatten()\n",
    "\n",
    "    # save to a temporary file\n",
    "    temp_file = generate_randStr() + \".wav\"\n",
    "    if not os.path.exists(env[\"TEMP_DIRECTORY\"]):\n",
    "        os.mkdir(env[\"TEMP_DIRECTORY\"])\n",
    "    writeAudio(env[\"TEMP_DIRECTORY\"] + temp_file, env[\"FRAME_RATE\"], recording)\n",
    "\n",
    "    # enhance audio with a Spectral Mask model\n",
    "    audio_enhancer.enhance_file(filename=env[\"TEMP_DIRECTORY\"] + temp_file, \n",
    "                                output_filename=env[\"TEMP_DIRECTORY\"] + temp_file)\n",
    "\n",
    "    return temp_file\n",
    "\n",
    "def add_audio(audio_data, username):\n",
    "    # open dataset\n",
    "    datasetFile = open(env[\"DATASET\"], \"r\")\n",
    "    dataset = json.load(datasetFile)\n",
    "    datasetFile.close()\n",
    "\n",
    "    # check user exists in dataset\n",
    "    if username not in dataset:\n",
    "        dataset[username] = {\"num_recordings\": 0, \"recordings\":[]}\n",
    "\n",
    "    # get credentials\n",
    "    user_recdir = env[\"AUDIO_DIRECTORY\"] + username + \"/\"\n",
    "    audio_name = username + \"_\" + str(dataset[username][\"num_recordings\"]) + \".wav\"\n",
    "\n",
    "    # update change\n",
    "    if not os.path.exists(user_recdir):\n",
    "        os.mkdir(user_recdir)\n",
    "    writeAudio(user_recdir + audio_name, env[\"FRAME_RATE\"], np.array(audio_data).flatten())\n",
    "    dataset[username][\"num_recordings\"] += 1\n",
    "    dataset[username][\"recordings\"].append(audio_name)\n",
    "\n",
    "    # update dataset file\n",
    "    datasetFile = open(env[\"DATASET\"], \"w\")\n",
    "    json.dump(dataset, datasetFile, indent=4)\n",
    "    datasetFile.close()\n",
    "\n",
    "\n",
    "def recog_audio(audio_data, username):\n",
    "    # save to a temporary file\n",
    "    temp_file = generate_randStr() + \".wav\"\n",
    "    if not os.path.exists(env[\"TEMP_DIRECTORY\"]):\n",
    "        os.mkdir(env[\"TEMP_DIRECTORY\"])\n",
    "    writeAudio(env[\"TEMP_DIRECTORY\"] + temp_file, env[\"FRAME_RATE\"], audio_data)\n",
    "\n",
    "    audio_data, _ = torchaudio.load(env[\"TEMP_DIRECTORY\"] + temp_file)\n",
    "\n",
    "    # embed the recording\n",
    "    embed_this = audio_classifier.encode_batch(audio_data).flatten()\n",
    "\n",
    "    # in this case, we read dataset and filter only the records that match (threshold, cosine)\n",
    "    datasetFile = open(env[\"DATASET\"], \"r\")\n",
    "    data_file = json.load(datasetFile)\n",
    "    datasetFile.close()\n",
    "\n",
    "    counter = 0\n",
    "    for file_name in data_file[username][\"recordings\"]:\n",
    "        signal, _ = torchaudio.load(env[\"AUDIO_DIRECTORY\"] + username + \"/\" + file_name)\n",
    "        embed_signal = audio_classifier.encode_batch(signal).flatten()\n",
    "\n",
    "        prob = 1 - sc.spatial.distance.cosine(embed_signal, embed_this)\n",
    "        display(str(prob))\n",
    "        if prob > env[\"EMBED_THRESHOLD\"]:\n",
    "            counter += 1\n",
    "\n",
    "    if counter >= env[\"USER_THRESHOLD\"] * data_file[username][\"num_recordings\"]:\n",
    "        display(\"Recognize user \" + username + \": True\")\n",
    "    else:\n",
    "        display(\"Recognize user \" + username + \": False\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UI functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = widgets.Output()\n",
    "\n",
    "def record_microphone():\n",
    "    env[\"TEMP_AUDIOCHECK\"] = False\n",
    "\n",
    "    # record audio\n",
    "    display(\"Recording...\")\n",
    "    temp_rec = sd.rec(int(env[\"RECORD_SECONDS\"] * env[\"FRAME_RATE\"]), \n",
    "                      samplerate=env[\"FRAME_RATE\"], channels=env[\"CHANNELS\"])\n",
    "    sd.wait() #buffer\n",
    "    \n",
    "    display(\"Recording completed.\")\n",
    "    \n",
    "    return temp_rec\n",
    "\n",
    "def recogAudio_main(data):\n",
    "    with output:\n",
    "        temp_rec = record_microphone()\n",
    "\n",
    "        if not env[\"TEMP_AUDIOCHECK\"]: # to prevent threads colliding\n",
    "            env[\"TEMP_AUDIOCHECK\"] = True\n",
    "\n",
    "            recog_audio(audio_data=temp_rec, username=env[\"USERNAME\"])\n",
    "\n",
    "def addAudio_main(data):\n",
    "    with output:\n",
    "        temp_rec = record_microphone()\n",
    "\n",
    "        if not env[\"TEMP_AUDIOCHECK\"]:\n",
    "            env[\"TEMP_AUDIOCHECK\"] = True\n",
    "\n",
    "            #temp_file = process_audio(temp_rec)\n",
    "            add_audio(audio_data = temp_rec, username=env[\"USERNAME\"])\n",
    "\n",
    "def stop_recording(data):\n",
    "    with output:\n",
    "        sd.stop() # stop recording\n",
    "        sd.wait()\n",
    "        display(\"Recording interrupted.\")\n",
    "        #main_job()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execution: User input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf740357870049cea6437ce66c1ce202",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='success', description='Record recognization', icon='microphone', style=ButtonStyle(), too…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "561b62394ade44c38b34d804f2174f2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='success', description='Record add dataset', icon='microphone', style=ButtonStyle(), toolt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0652da7956ce4eff9e7ded4fb494ce3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clear_output(wait=True)\n",
    "\n",
    "recordRecog_button.on_click(recogAudio_main)\n",
    "recordAdd_button.on_click(addAudio_main)\n",
    "#stop_button.on_click(stop_recording) # currently this doesn't work\n",
    "\n",
    "env[\"USERNAME\"] = input(\"Username: \")\n",
    "\n",
    "display(recordRecog_button, recordAdd_button, output)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
